{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac79c69",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-13T10:25:17.335520Z",
     "iopub.status.busy": "2023-11-13T10:25:17.334726Z",
     "iopub.status.idle": "2023-11-13T10:25:18.220709Z",
     "shell.execute_reply": "2023-11-13T10:25:18.219903Z"
    },
    "papermill": {
     "duration": 0.892744,
     "end_time": "2023-11-13T10:25:18.223041",
     "exception": false,
     "start_time": "2023-11-13T10:25:17.330297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e96f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:25:18.229369Z",
     "iopub.status.busy": "2023-11-13T10:25:18.228997Z",
     "iopub.status.idle": "2023-11-13T10:25:37.632836Z",
     "shell.execute_reply": "2023-11-13T10:25:37.631746Z"
    },
    "papermill": {
     "duration": 19.409485,
     "end_time": "2023-11-13T10:25:37.635192",
     "exception": false,
     "start_time": "2023-11-13T10:25:18.225707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "Setup complete ‚úÖ (4 CPUs, 31.4 GB RAM, 5122.2/8062.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb1136f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:25:37.642644Z",
     "iopub.status.busy": "2023-11-13T10:25:37.642142Z",
     "iopub.status.idle": "2023-11-13T10:25:37.646896Z",
     "shell.execute_reply": "2023-11-13T10:25:37.645873Z"
    },
    "papermill": {
     "duration": 0.010977,
     "end_time": "2023-11-13T10:25:37.649072",
     "exception": false,
     "start_time": "2023-11-13T10:25:37.638095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9dfb6d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:25:37.656152Z",
     "iopub.status.busy": "2023-11-13T10:25:37.655858Z",
     "iopub.status.idle": "2023-11-13T10:28:45.686559Z",
     "shell.execute_reply": "2023-11-13T10:28:45.685544Z"
    },
    "papermill": {
     "duration": 188.036643,
     "end_time": "2023-11-13T10:28:45.688518",
     "exception": false,
     "start_time": "2023-11-13T10:25:37.651875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.855325914149443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11140/11140 [01:15<00:00, 148.38it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1258/1258 [00:07<00:00, 161.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as pt\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def move_image(src_folder, dest_folder, image_name):\n",
    "    # Ê∫êÊñá‰ª∂ÁöÑË∑ØÂæÑ\n",
    "    src_path = os.path.join(src_folder, image_name)\n",
    "\n",
    "    # ÁõÆÊ†áÊñá‰ª∂ÁöÑË∑ØÂæÑ\n",
    "    dest_path = os.path.join(dest_folder, image_name)\n",
    "\n",
    "    # ÁßªÂä®Êñá‰ª∂\n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "\n",
    "def progress(list_, img_target, label_target, labels, data_path):\n",
    "    yy = tqdm(list_)\n",
    "    for csv_filename in yy:\n",
    "        df = pd.read_csv(os.path.join(data_path, csv_filename))\n",
    "        csv_name = csv_filename.split('.')[0]\n",
    "        txt_file_name = csv_name + '.txt'\n",
    "        img_file_name = csv_name + '.jpg'\n",
    "\n",
    "        for i in df.values:\n",
    "            # i-->[file_name, w, h, label, x1, y1, x2, y2]\n",
    "            txt_name, w, h, label, x1, y1, x2, y2 = i\n",
    "            if label not in [\"JAS39\", \"B52\", \"F14\", \"Tornado\", \"E2\", \"Mirage2000\", \"B2\", \"J20\", \"F4\"]:\n",
    "                pass\n",
    "            else:\n",
    "                move_image(data_path, img_target, img_file_name)\n",
    "                if label not in labels:\n",
    "                    labels.append(label)\n",
    "                label = labels.index(label)\n",
    "\n",
    "                x_ = (x1 + x2) / (2 * w)\n",
    "                y_ = (y1 + y2) / (2 * h)\n",
    "                w_ = (x2 - x1) / w\n",
    "                h_ = (y2 - y1) / h\n",
    "                with open(pt.join(label_target, txt_file_name), 'a') as f:\n",
    "                    f.write(f\"{label} {x_} {y_} {w_} {h_}\\n\")\n",
    "\n",
    "\n",
    "def generate_yaml(train_path, val_path, names, nc, base):\n",
    "    data = {\n",
    "        \"train\": train_path,\n",
    "        \"val\": val_path,\n",
    "        \"names\": names,\n",
    "        \"nc\": nc\n",
    "    }\n",
    "\n",
    "    with open(pt.join(base, 'mydata.yaml'), 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def main(save_path, source_path, scale):\n",
    "    # ÂàõÂª∫‰øùÂ≠òtxtÁöÑË∑ØÂæÑ\n",
    "    base = save_path\n",
    "    img_path = pt.join(base, 'images')\n",
    "    label_path = pt.join(base, 'labels')\n",
    "    img_path_train = pt.join(img_path, 'train')\n",
    "    img_path_val = pt.join(img_path, 'val')\n",
    "    label_path_train = pt.join(label_path, 'train')\n",
    "    label_path_val = pt.join(label_path, 'val')\n",
    "    exists(img_path_train)\n",
    "    exists(img_path_val)\n",
    "    exists(label_path_train)\n",
    "    exists(label_path_val)\n",
    "\n",
    "    data_path = source_path\n",
    "    filenames = os.listdir(data_path)\n",
    "    csv_filenames = [filename for filename in filenames if filename.endswith('.csv')]\n",
    "\n",
    "    # ÊåâÊØî‰æãÂ∞ÜcsvÊñá‰ª∂ÂàÜÊàêtrainÂíåval\n",
    "    labels1 = {}\n",
    "    for csv_name in csv_filenames:\n",
    "        df = pd.read_csv(os.path.join(data_path, csv_name))\n",
    "        for i in df.values:\n",
    "            txt_name, w, h, label, x1, y1, x2, y2 = i\n",
    "            if label in labels1:\n",
    "                labels1[label].append(csv_name)\n",
    "            else:\n",
    "                labels1[label] = [csv_name]\n",
    "            break\n",
    "\n",
    "    train_files = []\n",
    "    valid_files = []\n",
    "    for i in labels1.values():\n",
    "        random.shuffle(i)\n",
    "        num_train = int(len(i) * scale)\n",
    "\n",
    "        train_files.extend(i[:num_train])\n",
    "        valid_files.extend(i[num_train:])\n",
    "\n",
    "    Alabels = []\n",
    "    print(len(train_files) / len(valid_files))\n",
    "\n",
    "    progress(train_files, img_path_train, label_path_train, Alabels, data_path)\n",
    "    progress(valid_files, img_path_val, label_path_val, Alabels, data_path)\n",
    "\n",
    "    names = {i: name for i, name in enumerate(Alabels)}\n",
    "    nc = len(Alabels)\n",
    "    generate_yaml(img_path_train, img_path_val, names, nc, base)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(save_path='/kaggle/working/data',\n",
    "         source_path='/kaggle/input/militaryaircraftdetectiondataset/dataset',\n",
    "         scale=0.9\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52d4d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:28:45.766336Z",
     "iopub.status.busy": "2023-11-13T10:28:45.765481Z",
     "iopub.status.idle": "2023-11-13T10:51:06.260940Z",
     "shell.execute_reply": "2023-11-13T10:51:06.259678Z"
    },
    "papermill": {
     "duration": 1340.537199,
     "end_time": "2023-11-13T10:51:06.263832",
     "exception": false,
     "start_time": "2023-11-13T10:28:45.726633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 175MB/s]\n",
      "Ultralytics YOLOv8.0.208 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/data/mydata.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 25.0MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012603 parameters, 3012587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/labels/train... 2250 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2250/2250 [00:01<00:00, 1170.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/0659b84f8272d49753431dc808b8d4e1.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/37cef25b6530c45a02acb1d30b56a15b.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/4ef1fa6020f23711cc0e06dc1e7dfdbc.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/7a1054ee4e1158ad3bb2d2d7b1308cc6.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/81132e8d96bf76ceac037b03839c82ab.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/88c2d4d1d4f5ab539558cf4129cd9ef2.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/a912ac8f44762b44a4916ad011437fbb.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/d4a19e6524ed06786bc75802388069cd.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/data/images/train/fe26e23dabe4618337df064573717487.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/labels/val... 255 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 255/255 [00:00<00:00, 972.37it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/labels/val.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/15      2.37G      1.064      3.452       1.25         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.67it/s]\n",
      "                   all        255        421       0.11      0.263      0.116     0.0853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/15      2.35G      1.088      2.851      1.247         64        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.43it/s]\n",
      "                   all        255        421      0.159      0.369      0.216      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/15      2.34G      1.081      2.651      1.248         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:20<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.45it/s]\n",
      "                   all        255        421      0.174      0.404      0.213      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/15      2.35G       1.08      2.536      1.248         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:19<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.71it/s]\n",
      "                   all        255        421      0.187      0.364      0.244      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/15      2.33G      1.058       2.38       1.23         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:20<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.88it/s]\n",
      "                   all        255        421      0.289      0.486      0.302      0.224\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/15      2.35G     0.9751      2.391      1.199         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:20<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.52it/s]\n",
      "                   all        255        421       0.24      0.436      0.279      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/15      2.34G     0.9393      2.225      1.178         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.63it/s]\n",
      "                   all        255        421       0.27      0.416      0.345       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/15      2.35G      0.918      2.023      1.155         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  3.18it/s]\n",
      "                   all        255        421      0.348      0.392      0.393       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/15      2.34G     0.8503      1.898      1.114         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.74it/s]\n",
      "                   all        255        421      0.283      0.465       0.38      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/15      2.34G     0.8323      1.791      1.105         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.67it/s]\n",
      "                   all        255        421      0.384      0.393       0.38      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/15      2.35G     0.7887      1.699      1.074         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  3.18it/s]\n",
      "                   all        255        421      0.396      0.504      0.447      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/15      2.34G     0.7623      1.622      1.059         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:19<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.70it/s]\n",
      "                   all        255        421      0.376      0.509      0.457      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/15      2.34G     0.7309      1.525      1.045         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:16<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.87it/s]\n",
      "                   all        255        421      0.442      0.486      0.482       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/15      2.35G      0.732       1.49      1.043         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:19<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  2.71it/s]\n",
      "                   all        255        421      0.458      0.532       0.51      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/15      2.34G     0.6806      1.362      1.015         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:18<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.56it/s]\n",
      "                   all        255        421      0.456      0.541      0.526      0.429\n",
      "\n",
      "15 epochs completed in 0.357 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.53it/s]\n",
      "                   all        255        421      0.455      0.541      0.526      0.429\n",
      "                   B52        255         57      0.557      0.737      0.728      0.552\n",
      "                 JAS39        255         42      0.282      0.381      0.347      0.284\n",
      "            Mirage2000        255         34       0.31      0.294      0.224      0.174\n",
      "               Tornado        255         51      0.392      0.373      0.399      0.352\n",
      "                    F4        255         53      0.574      0.408      0.516      0.391\n",
      "                    B2        255         39      0.769      0.769      0.835      0.678\n",
      "                    E2        255         36       0.53      0.889      0.784      0.632\n",
      "                   F14        255         68      0.416      0.382      0.376      0.325\n",
      "                   J20        255         41      0.263      0.634      0.528      0.472\n",
      "Speed: 0.7ms preprocess, 2.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(data='/kaggle/working/data/mydata.yaml', epochs=15, imgsz=640, lrf=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1558.472404,
   "end_time": "2023-11-13T10:51:12.475316",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-13T10:25:14.002912",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
